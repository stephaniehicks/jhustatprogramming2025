[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Additional Resources",
    "section": "",
    "text": "The pre-requisite for this course is 140.776. All of the lecture material is available online. I encourage those enrolled in 140.777 to review the material to ensure you are familiar with these topics. Please use this as a resource to fill in any gaps in knowledge that you might have missed to ensure your success in this course, including:\n\nFamilarity with tidy principles and programming in the tidyverse\nWriting functions and loops in R\nDebugging code in R\nBest practices for data analyses\nLeveraging Python within R using reticulate"
  },
  {
    "objectID": "resources.html#pre-requisites",
    "href": "resources.html#pre-requisites",
    "title": "Additional Resources",
    "section": "",
    "text": "The pre-requisite for this course is 140.776. All of the lecture material is available online. I encourage those enrolled in 140.777 to review the material to ensure you are familiar with these topics. Please use this as a resource to fill in any gaps in knowledge that you might have missed to ensure your success in this course, including:\n\nFamilarity with tidy principles and programming in the tidyverse\nWriting functions and loops in R\nDebugging code in R\nBest practices for data analyses\nLeveraging Python within R using reticulate"
  },
  {
    "objectID": "resources.html#resources-for-best-practice-for-data-analyses",
    "href": "resources.html#resources-for-best-practice-for-data-analyses",
    "title": "Additional Resources",
    "section": "Resources for best practice for data analyses",
    "text": "Resources for best practice for data analyses\nIn addition to this topic being covered in 140.776, we have provided additional resources for improving your skills of writing good data analyses. This also includes avoiding common pitfalls. Here are some resources that you might find useful. If you have recommendations on other resources that should be added to the list, please share and we will gladly post them.\n\n(Some) Best practices for writing up a data analysis\nTen simple rules for effective statistical practice\nGood enough practices in scientific computing\nData Organization in Spreadsheets\nGood data analysis"
  },
  {
    "objectID": "readings/00-quarto/index.html",
    "href": "readings/00-quarto/index.html",
    "title": "Authoring projects and websites with Quarto",
    "section": "",
    "text": "Quarto provides a unified authoring framework for data science, combining your code, its results, and your prose.\nQuarto documents are fully reproducible and support dozens of output formats, like PDFs, Word files, presentations, and more.\nQuarto files are designed to be used in three ways:\n\nFor communicating to decision makers, who want to focus on the conclusions, not the code behind the analysis.\nFor collaborating with other data scientists (including future you!), who are interested in both your conclusions, and how you reached them (i.e. the code).\nAs an environment in which to do data science, as a modern day lab notebook where you can capture not only what you did, but also what you were thinking.\n\n\n\n\n\n\n\nImportant\n\n\n\nQuarto is a command line interface tool, not an R package.\nThis means that help is, by-and-large, not available through ? in the R console.\nAnd not to add to the confusion, but there is an quarto R package that has helper functions for you to use in R to e.g. check the Quarto version installed, etc.\n\n\nFormally, Quarto is a publishing system built on Pandoc that allows users to create dynamic content using R, Python, Julia, and ObservableJS (with plans to add more languages too!).\n\n\n\nA schematic representing the multi-language input versatility of Quarto\n\n\n\n\nArt by Allison Horst. Be sure to check out the rest of Allison’s seriously cute Quarto penguin art in the #rstudioconf2022 keynote talk, Hello Quarto, by Julie Lowndes & Mine Çetinkaya-Rundel!\n\n\n\nYou need the Quarto command line interface (Quarto CLI), but you don’t need to explicitly install it or load it, as RStudio automatically does both when needed.\n\nhttps://quarto.org/docs/get-started\nhttps://formulae.brew.sh/cask/quarto (this is my preferred way using home brew)"
  },
  {
    "objectID": "readings/00-quarto/index.html#introduction",
    "href": "readings/00-quarto/index.html#introduction",
    "title": "Authoring projects and websites with Quarto",
    "section": "",
    "text": "Quarto provides a unified authoring framework for data science, combining your code, its results, and your prose.\nQuarto documents are fully reproducible and support dozens of output formats, like PDFs, Word files, presentations, and more.\nQuarto files are designed to be used in three ways:\n\nFor communicating to decision makers, who want to focus on the conclusions, not the code behind the analysis.\nFor collaborating with other data scientists (including future you!), who are interested in both your conclusions, and how you reached them (i.e. the code).\nAs an environment in which to do data science, as a modern day lab notebook where you can capture not only what you did, but also what you were thinking.\n\n\n\n\n\n\n\nImportant\n\n\n\nQuarto is a command line interface tool, not an R package.\nThis means that help is, by-and-large, not available through ? in the R console.\nAnd not to add to the confusion, but there is an quarto R package that has helper functions for you to use in R to e.g. check the Quarto version installed, etc.\n\n\nFormally, Quarto is a publishing system built on Pandoc that allows users to create dynamic content using R, Python, Julia, and ObservableJS (with plans to add more languages too!).\n\n\n\nA schematic representing the multi-language input versatility of Quarto\n\n\n\n\nArt by Allison Horst. Be sure to check out the rest of Allison’s seriously cute Quarto penguin art in the #rstudioconf2022 keynote talk, Hello Quarto, by Julie Lowndes & Mine Çetinkaya-Rundel!"
  },
  {
    "objectID": "readings/00-quarto/index.html#prerequisites",
    "href": "readings/00-quarto/index.html#prerequisites",
    "title": "Authoring projects and websites with Quarto",
    "section": "",
    "text": "You need the Quarto command line interface (Quarto CLI), but you don’t need to explicitly install it or load it, as RStudio automatically does both when needed.\n\nhttps://quarto.org/docs/get-started\nhttps://formulae.brew.sh/cask/quarto (this is my preferred way using home brew)"
  },
  {
    "objectID": "readings/00-quarto/index.html#qmd-files",
    "href": "readings/00-quarto/index.html#qmd-files",
    "title": "Authoring projects and websites with Quarto",
    "section": ".qmd files",
    "text": ".qmd files\nQuarto files end in a .qmd. This is short for quarto markdown.\n\n\n\n\n\n\nNoteNote\n\n\n\nThese files are decoupled from RStudio IDE and there are plugins to work with .qmd files for\n\nVSCode\nJupyterLab\nRStudio\n\n\n\n\nRendering\nUse the  Render button in the RStudio IDE to render the file and preview the output with a single click or keyboard shortcut (⇧⌘K).\n\n\n\n\n\nIf you prefer to automatically render whenever you save, you can check the Render on Save option on the editor toolbar. The preview will update whenever you re-render the document. Side-by-side preview works for both HTML and PDF outputs.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nDocuments can also be rendered from the R console via the quarto package:\n\n\nCode run in the R Console\n\ninstall.packages(\"quarto\")\nquarto::quarto_render(\"hello.qmd\")\n\nAnd documents can also be rendered from the command line:\n\n\nCode run in the command line\n\n# render single document (always executes code)\nquarto render document.qmd\n\n# render project subdirectory (always executes code)\nquarto render articles\n\n\n\n\nHow rendering works\nWhen you render a Quarto document, first knitr executes all of the code chunks and creates a new markdown (.md) document which includes the code and its output. The markdown file generated is then processed by pandoc, which creates the finished format. The Render button encapsulates these actions and executes them in the right order for you.\n\n\n\n\n\nWhen rendering, Quarto generates a new file that contains selected text, code, and results from the .qmd file. The new file can be an HTML, PDF, MS Word document, presentation, website, book, interactive document, or other format.\n\n\n\nAuthoring\nIn the image below we can see the same document in the two modes of the RStudio editor:\n\nvisual (on the left)\nsource (on the right)\n\nRStudio’s visual editor offers an WYSIWYM authoring experience for markdown. For formatting (e.g. bolding text) you can use the toolbar, a keyboard shortcut (⌘B), or the markdown construct (**bold**).\nYou can toggle back and forth these two modes by clicking on Source and Visual in the editor toolbar (or using the keyboard shortcut ⌘⇧ F4).\n\n\n\n\n\n\n\nHow does multi-language support work?\n\n\n\n\n\n\nTipQuarto supports multiple languages\n\n\n\nThese languages include\n\nR\nPython\nJulia\nObservable javascript\n\nQuarto can also interchange between languages using Apache Arrow.\n\n\nThe idea behind how quarto supports multi-language code is that the code output is “frozen” after it is rendered.\nIn this way, code output is not recomputed, unless you want it to."
  },
  {
    "objectID": "readings/00-quarto/index.html#r-markdown-vs-quarto",
    "href": "readings/00-quarto/index.html#r-markdown-vs-quarto",
    "title": "Authoring projects and websites with Quarto",
    "section": "R Markdown vs Quarto",
    "text": "R Markdown vs Quarto\nSome high-level differences include\n\nStandardized YAML across formats\nDecoupled from RStudio\nMore consistent presentation across formats\nTab Panels\nCode Highlighting\n\n\nCode block options\nAnother noticeable difference are options for code blocks. Rather than being in the header of the code block, options are moved to within the code block using the #| (hash-pipe) for each line.\nThis is a code block for R Markdown:\n```{r setup, include=FALSE}\nlibrary(tidyverse)\nlibrary(tidytext)\n```\nThis is a code block for Quarto:\n```{r}\n#| label: \"setup\"\n#| include: false\nlibrary(tidyverse)\nlibrary(tidytext)\n```\n\n\nOutput Options\nThere are a wide variety of output options available for customizing output from executed code.\nAll of these options can be specified either\n\nglobally (in the document front-matter) or\nper code-block\n\nFor example, here’s a modification of the Python example to specify that we don’t want to “echo” the code into the output document:\n---\ntitle: \"My Document\"\nexecute:\n  echo: false\njupyter: python3\n---\nNote that we can override this option on a per code-block basis. For example:\n```{python}\n#| echo: true\n\nimport matplotlib.pyplot as plt\nplt.plot([1,2,3,4])\nplt.show()\n```\nCode block options available for customizing output include:\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\neval\nEvaluate the code chunk (if false, just echos the code into the output).\n\n\necho\nInclude the source code in output\n\n\noutput\nInclude the results of executing the code in the output (true, false, or asis to indicate that the output is raw markdown and should not have any of Quarto’s standard enclosing markdown).\n\n\nwarning\nInclude warnings in the output.\n\n\nerror\nInclude errors in the output (note that this implies that errors executing code will not halt processing of the document).\n\n\ninclude\nCatch all for preventing any output (code or results) from being included (e.g. include: false suppresses all output from the code block).\n\n\n\nHere’s a example with r code blocks and some of these additional options included:\n---\ntitle: \"Knitr Document\"\nexecute:\n  echo: false\n---\n\n```{r}\n#| warning: false\n\nlibrary(ggplot2)\nggplot(airquality, aes(Temp, Ozone)) + \n  geom_point() + \n  geom_smooth(method = \"loess\", se = FALSE)\n```\n\n```{r}\nsummary(airquality)\n```\n\n\n\n\n\n\nTip\n\n\n\nWhen using the Knitr engine, you can also use any of the available native options (e.g. collapse, tidy, comment, etc.).\nSee the Knitr options documentation for additional details. You can include these native options in option comment blocks as shown above, or on the same line as the {r} as shown in the Knitr documentation.\n\n\n\n\nMargin content\nYou can place content within the right margin of Quarto document. For example, here we use the .column-margin class to place an image in the margin:\n::: {.column-margin}\nWe know from *the first fundamental theorem of calculus* that for $x$ in $[a, b]$:\n\n$$\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).$$\n:::\n\n\nWe know from the first fundamental theorem of calculus that for \\(x\\) in \\([a, b]\\):\n\\[\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).\\]\n\n\nMargin Figures\nFigures that you create using code blocks can be placed in the margin by using the column: margin code block option.\nIf the code produces more than one figure, each of the figures will be placed in the margin.\n\n```{r}\n#| label: fig-mtcars\n#| fig-cap: \"MPG vs horsepower, colored by transmission.\"\n#| column: margin\nlibrary(ggplot2)\nmtcars2 &lt;- mtcars\nmtcars2$am &lt;- factor(\n  mtcars$am, labels = c('automatic', 'manual')\n)\nggplot(mtcars2, aes(hp, mpg, color = am)) +\n  geom_point() +\n  geom_smooth(formula = y ~ x, method = \"loess\") +\n  theme(legend.position = 'bottom')\n```\n\n\n\n\n\n\n\n\nFigure 1: MPG vs horsepower, colored by transmission.\n\n\n\n\n\n\nMargin Tables\nYou an also place tables in the margin of your document by specifying column: margin.\n\n```{r}\n#| column: margin\nknitr::kable(\n  mtcars[1:6, 1:3]\n)\n```\n\n\n\n\n\n\nmpg\ncyl\ndisp\n\n\n\n\nMazda RX4\n21.0\n6\n160\n\n\nMazda RX4 Wag\n21.0\n6\n160\n\n\nDatsun 710\n22.8\n4\n108\n\n\nHornet 4 Drive\n21.4\n6\n258\n\n\nHornet Sportabout\n18.7\n8\n360\n\n\nValiant\n18.1\n6\n225\n\n\n\n\n\n\nCode line numbers\nIf you want to display line numbers alongside the code block, add the code-line-numbers option. For example:\nformat:\n  html:\n    code-line-numbers: true\nHere’s how a code block with line numbers would display throughout the document:\nlibrary(ggplot2)\nmtcars2 &lt;- mtcars\nmtcars2$am &lt;- factor(\n  mtcars$am, labels = c('automatic', 'manual')\n)\nggplot(mtcars2, aes(hp, mpg, color = am)) +\n  geom_point() +\n  geom_smooth(formula = y ~ x, method = \"loess\") +\n  theme(legend.position = 'bottom')\nYou can also enable line numbers for an individual code block using the code-line-numbers attribute.\n\n\nShould you switch to quarto?\n\nShould you switch to Quarto? Not necessarily. If you find R Markdown meets your need, you can definitely stay there. It is not imperative to switch. - Yihui Xie\n\n\n\nhttps://yihui.org/en/2022/04/quarto-r-markdown/"
  },
  {
    "objectID": "readings/00-quarto/index.html#project",
    "href": "readings/00-quarto/index.html#project",
    "title": "Authoring projects and websites with Quarto",
    "section": "Project",
    "text": "Project\nHere are the general steps for creating a Quarto project in RStudio:\n\nCreate a new Quarto project\nEdit _quarto.yml file\nAdd / delete relevant content\nRender the project"
  },
  {
    "objectID": "readings/00-quarto/index.html#website",
    "href": "readings/00-quarto/index.html#website",
    "title": "Authoring projects and websites with Quarto",
    "section": "Website",
    "text": "Website\nHere are the general steps for creating a Quarto website:\n\nCreate a new Quarto project\nEdit _quarto.yml file\nAdd / delete relevant content\nRender the website\nDeploy the website\n\n\n\n\n\n\n\nTipDeploying a website\n\n\n\nquarto publish can push and update a number of different kinds of webhosts. You will need credentials to publish to each of these.\nquarto publish gh-pages    # GitHub Pages\nquarto publish quarto-pub  # Quarto.pub \nquarto publish netlify     # Netlify\nquarto publish connect     # RStudio Connect"
  },
  {
    "objectID": "readings/00-quarto/index.html#freeze-results-and-avoid-recomputing",
    "href": "readings/00-quarto/index.html#freeze-results-and-avoid-recomputing",
    "title": "Authoring projects and websites with Quarto",
    "section": "Freeze Results and avoid recomputing",
    "text": "Freeze Results and avoid recomputing\nFreezing code output is generally used when you have either\n\nA large number of collaborators or\nMany computational documents created over a longer period of time\nA project with different types of file formats from different languages (e.g. .qmd, .ipynb, .Rmd)\n\nIn the above cases, it can be challenging to fully re-execute every document when you render the site.\nThis could be because some documents have esoteric or environment-specific requirements (e.g. require access/authentication to a data source) or due to general fragility of dependencies over time.\nUsing freeze ensures that you can always reproducibly render your site.\nThe computational results of documents executed with freeze are stored in the _freeze/ directory, and re-used when needed to fulfill document renders.\nYou should check the contents of _freeze/ into version control so that others rendering the project don’t need to reproduce your computational environment to render it in their environment.\n\n\n\n\n\n\nNoteNote\n\n\n\nYou will still want to take care to fully re-render your project when things outside of source code change (e.g. input data).\nYou can remove previously frozen output by deleting the _freeze folder at the root of your project.\n\n\nFor example, consider the _quarto.yml file.\nOne argument in the file is the freeze option to denote that computational documents should never be re-rendered during a global project render, or alternatively only be re-rendered when their source file changes:\nproject:\n  title: \"qmd_rmd\"\n  type: website\n  output-dir: docs\n  \nexecute:\n  freeze: true  # never re-render during project render\nproject:\n  title: \"qmd_rmd\"\n  type: website\n  output-dir: docs\n\nexecute:\n  freeze: auto  # re-render only when source changes\n\n\n\n\n\n\nNoteNote\n\n\n\nThe freeze option in the _quarto.yml file controls whether execution occurs during global project renders.\nIf you do an incremental render of either a single document or a project sub-directory then code is always executed. For example:\n\n\nTerminal\n\n# render single document (always executes code)\nquarto render document.qmd\n\n# render project subdirectory (always executes code)\nquarto render articles"
  },
  {
    "objectID": "readings.html",
    "href": "readings.html",
    "title": "Important reading materials",
    "section": "",
    "text": "The following contains relevant reading materials you should read prior to each class:\n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nAuthor\n\n\n\n\n\n\n\n\n2025-10-23\n\n\n(Some) Best practices for writing up a data analysis\n\n\nStephanie Hicks\n\n\n\n\n\n\n2025-10-23\n\n\nAuthoring projects and websites with Quarto\n\n\nStephanie Hicks\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lectures/00-course-intro/index.html",
    "href": "lectures/00-course-intro/index.html",
    "title": "Welcome to the course",
    "section": "",
    "text": "Tip\n\n\n\nBefore each class, there will be a set optional of pre-lecture activities and/or readings. We ask students to scan these resources prior to class to familiarize yourself with the topic. During lecture, we will go into greater detail and will answer questions about the topic. However, familarizing yourself with the topic in advance will be useful to you as we will practice these topics after the lecture in a set of in-class activities.\n\n\n\nAuthoring projects and websites with Quarto\n(Some) Best practices for writing up a data analysis"
  },
  {
    "objectID": "lectures/00-course-intro/index.html#acknowledgements",
    "href": "lectures/00-course-intro/index.html#acknowledgements",
    "title": "Welcome to the course",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nr4ds book: https://r4ds.hadley.nz/quarto\nQuarto Publishing System: https://quarto.org"
  },
  {
    "objectID": "lectures/00-course-intro/index.html#learning-objectives",
    "href": "lectures/00-course-intro/index.html#learning-objectives",
    "title": "Welcome to the course",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\n\n\n\n\nNoteLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nGet an overview of the course (including staff, format, grading, etc)\nFamiliarize yourself with best practices for building good data analyses\nInstall and use an Integrated Developer Evironment (IDE) to perform statistial programming and data analyses\nRecognize what are Quarto files and how they are different from RMarkdown files or Python notebooks\nBe able to create a Quarto project and Quarto website for yourself"
  },
  {
    "objectID": "lectures/00-course-intro/index.html#slides",
    "href": "lectures/00-course-intro/index.html#slides",
    "title": "Welcome to the course",
    "section": "Slides",
    "text": "Slides\n\nLecture 00: Welcome and course overview"
  },
  {
    "objectID": "lectures/00-course-intro/index.html#summary",
    "href": "lectures/00-course-intro/index.html#summary",
    "title": "Welcome to the course",
    "section": "Summary",
    "text": "Summary\n\nAccess all course material on CoursePlus and course website (https://www.stephaniehicks.com/jhustatprogramming2025)\nLectures will be recorded followed by an in-class activity. Later in the course, the in-class activity will be to work on the final project\nBuilding good data analyses takes practice, but thinking about the audience, the question, and the key conclusions can be helpful to increasing clarity and trust\nIntegrated developer environment (IDEs) can make you more efficient as a programmer!\nQuarto is an open-source scientific and technical publishing system to create reproducible, production quality articles, presentations, dashboards, websites, blogs, and books in HTML, PDF, MS Word, and more\nYou can think of Quarto as a natural successor to RMarkdown with code chunks"
  },
  {
    "objectID": "lectures/00-course-intro/index.html#additional-practice",
    "href": "lectures/00-course-intro/index.html#additional-practice",
    "title": "Welcome to the course",
    "section": "Additional practice",
    "text": "Additional practice\nHere are some additional practice questions to help you think about the material discussed.\n\n\n\n\n\n\nNoteQuestions\n\n\n\n\nIn either RStudio or VSCode, create a new Quarto document. Read the instructions. Practice running the chunks individually. Then render the document and practice the appropriate keyboard short cut. Verify that you can modify the code, re-run it, and see modified output.\nCreate one new Quarto document for each of the three built-in formats: HTML, PDF and Word. Render each of the three documents. How do the outputs differ? How do the inputs differ? (You may need to install LaTeX in order to build the PDF output — RStudio will prompt you if this is necessary.)\nCreate a new Quarto website to create a website for yourself. Explore different themes and try adding new pages to the website to describe an “About Me” page."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome to the Course Website for PH.140.777 Statistical Programming Paradigms and Workflows!"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Welcome",
    "section": "Overview",
    "text": "Overview\nComputing and programming are fundamental skills for applied statisticians to efficiently demonstrate the performance of their models with data, to develop reproducible data analyses or robust software, and to effectively communicate their own research interests. However, these skills are often not taught in the classroom, often making it challenging to learn these skills “on the job”.\nThis hands-on course will cover advanced statistical computing programming paradigms and workflows required for the research and application of statistical methods. Students will be expected to complete readings prior to class, attend lectures to dive deeper into those topics in class, participate in classroom activities, complete projects (both solo and group) practicing and reinforcing the computing and programming skills. There will be a final group project, which will include a major class presentation."
  },
  {
    "objectID": "index.html#course-information",
    "href": "index.html#course-information",
    "title": "Welcome",
    "section": "Course Information",
    "text": "Course Information\n\nCourse Staff: Prof. Stephanie Hicks and TBA TAs\nLectures: 1:30-2:50pm Tuesday and Thursday. See CoursePlus for location details.\nOffice Hours: See CoursePlus for location details."
  },
  {
    "objectID": "index.html#course-details",
    "href": "index.html#course-details",
    "title": "Welcome",
    "section": "Course Details",
    "text": "Course Details\nAll course details are available on the Course page. The syllabus is available on CoursePlus."
  },
  {
    "objectID": "lectures.html",
    "href": "lectures.html",
    "title": "Course content",
    "section": "",
    "text": "Course content for each lecture is below:\n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nAuthor\n\n\n\n\n\n\n\n\n2025-10-23\n\n\nWelcome to the course\n\n\nStephanie Hicks\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "readings/00-best-practices-data-analysis/index.html",
    "href": "readings/00-best-practices-data-analysis/index.html",
    "title": "(Some) Best practices for writing up a data analysis",
    "section": "",
    "text": "In this class, you will write up data analyses where you are practicing one or more concepts that we have learned in the class. One of the questions that often arises is “What makes a good data analysis write up?”.\nThis is a fantastic question and it’s one of those things that once you have seen enough examples of good data analyses or once you have written enough of them yourself, it is easier to recognize. For those that are new(-ish) to writing up good data analyses, I am here to share the bad news that I do not have simple check list for you to follow. However, I have put together some thoughts that should hopefully help you write better data analyses after reading the thoughts below.\n\n\nA primary goal of building a data analysis is to extract knowledge and insights from examining data (J. W. Tukey 1962; W. Tukey and Wilk 1966). This knowledge is often encoded into machine learning algorithms or related data products to facilitate use by large numbers of users. Yet, the discussion of how to build a data analysis that is trusted by its users often proceeds without explicit reference to an audience or consumer for whom the data analysis is being developed.\nIndeed, there is much for a data analyst to consider on their own with respect to statistical techniques, visualization methods, data processing approaches, and computational algorithms that do not involve the needs or requirements of an audience member in particular. However, a critical goal for many data analyses is to be useful or persuasive to another person (Kimball 1957). The audience could range from simply the person doing the analysis to a much larger external group.\nIt is worth to think about how to build data analyses that are trustworthy and for others to have trust in the work that they produce. The extent to which results from data analyses are used for key policy decisions enhances the need for trust between analyst and audience. Broderick et al. (2023) note that complex data analyses with long data pipelines present numerous opportunities for trust to break down. In particular, they note that trust can break down if the evidence generated by an analysis is not useful for decision-making. An alternative framework is proposed by Yu and Barter (2024), who argue that trustworthiness in the data science life cycle can be achieved through building analyses that have predictability, computability, and stability. A principle that ties both frameworks together is the characterization of the development of trust as primarily being in the hands of the analyst, via decisions made about study design, data collection, model choice, and other aspects of the data science process.\nOne approach to addressing the challenge of building a useful analysis is to consider the audience as part of the design of the analysis itself. Hence, it can be a valuable exercise to think about who the audience is that you (as the data analyst) have in mind when you build the data analysis. Some examples of who a data analysis write up is written for could include:\n\nA primary non-technical audience: This could be a collaborator or client. They might be interested a higher-level, non-technical pass of the write up (primarily focused on the introduction, main figures, and conclusions to find out what you learned). They may or may not read the technical details to see if there is something that stands out or unexpected. Here you want to think about building your data analysis with their expertise in mind where you prioritize the type of information that they found most relevant in a data analysis (for example, maybe they need to see a specific type of plot) and then move more of the technical details to the appendix.\nA secondary non-technical audience: This is likely a non-technical manager, an executive, or someone who is crafting new policies based the results of your data analysis. These individuals will skim most of the components of your analysis and will be focused on the “headlines” of your work. You want to summarize your key findings clearly and succinctly.\nA primary or secondary technical audience: This could be a technical manager or an advisor. Here, this individual will carefully read all components, including the main technical details in your data analysis. They may challenge you to justify your data analytic choices and push you to improve your technical writing, your code, and data visualizations. Here, you want to make sure the details of your report are easily readable, succinct (not a list of everything you did over the whole analysis), and compelling to justify the results you summarize in the conclusions.\n\n\n\n\n\n\n\nNote\n\n\n\nFor more information on the audience of a data analysis, I encourage you to read Quantifying the Alignment of a Data Analysis Between Analyst and Audience (McGowan, Peng, and Hicks 2025).\n\n\n\n\n\nNow that you have an audience in mind, the next question you might have is how to structure a data analysis. This is typically different from other professional writing you have done (e.g. research article for a peer-reviewed journal) because the structure of analyses can vary so much depending on the audience. In traditional research articles, there is typically less flexibility. The other thing I should add is that this is not a skill people are born with it. It takes practice to hone this skill of writing good data analyses and the more you do it, the easier it will become.\nGenerally speaking though, the structure of data analysis will include:\n\nAn introduction and/or motivation of the problem being addressed\nWhat is the question being asked that you will then investigate with data?\nThe body (may or may not include many of the technical details)\nKey conclusions and/or discussion of limitations of the data analysis\nAppendix (where often more of the technical detail goes if writing for a non-technical audience)\n\nThe ``body” is often quite different depending on who the audience is. You want to describe the computational approach(es) you took to investigate the question asked with the data available. Ideally, you are concise, but also it has to be informative.\nFor example, instead of saying “I used regression”, you could say “I fit a linear regression model to the price of diamonds using the size and clarity of the diamond as predictors”. You want to justify why these are relevant features and the body will often contain many plots or tables. This choice is up to you, but if you think a plot would be helpful to include to explain to the audience an important detail, then include it. You don’t want to include dozens or hundreds of plots without explanation or rationale why you included these plots.\n\n\nSome things to consider are:\n\nWho is your intended audience for the data analysis?\nWhat is the question you are trying to answer?\nWhy is this question important or interesting? If appropriate, mention prior work or background that motivated this analysis\nWhat data are you using? Identify the dataset(s), their source, and key features. This should be concise as the data can be described in greater detail elsewhere in the write up.\nWhat is the expected contribution or insight? What does this analysis add or clarify?\n\n\n\n\nSome things to consider are:\n\nYou want to clearly label figures, give them informative captions, and refer to them in the text in the order they in the paper (e.g. Figure 1, 2, 3, etc).\nShowing the code could be fine for certain audiences, but it could also be useful to just show the output of the code for other audiences as evidence for the results you summarize in the conclusions.\n\n\n\n\nSome things to consider are:\n\nWhat did you learn from the analysis?\nWhat are the limiations of the data used or the data analysis?\nWere you able to answer the original question asked or a different question?\n\n\n\n\n\n\nWhen in doubt, use shorter words and sentences.\nA common pitfall in report writing is to recount your thought process step by step — for example: “First I did this, but it didn’t work. Then I tried something else and found A, B, and C. I wasn’t sure what to make of B, but C seemed interesting, so I followed up with D and E.” Avoid this approach. While your attention to detail is commendable, this style comes across as unpolished and unfocused."
  },
  {
    "objectID": "readings/00-best-practices-data-analysis/index.html#audience",
    "href": "readings/00-best-practices-data-analysis/index.html#audience",
    "title": "(Some) Best practices for writing up a data analysis",
    "section": "",
    "text": "A primary goal of building a data analysis is to extract knowledge and insights from examining data (J. W. Tukey 1962; W. Tukey and Wilk 1966). This knowledge is often encoded into machine learning algorithms or related data products to facilitate use by large numbers of users. Yet, the discussion of how to build a data analysis that is trusted by its users often proceeds without explicit reference to an audience or consumer for whom the data analysis is being developed.\nIndeed, there is much for a data analyst to consider on their own with respect to statistical techniques, visualization methods, data processing approaches, and computational algorithms that do not involve the needs or requirements of an audience member in particular. However, a critical goal for many data analyses is to be useful or persuasive to another person (Kimball 1957). The audience could range from simply the person doing the analysis to a much larger external group.\nIt is worth to think about how to build data analyses that are trustworthy and for others to have trust in the work that they produce. The extent to which results from data analyses are used for key policy decisions enhances the need for trust between analyst and audience. Broderick et al. (2023) note that complex data analyses with long data pipelines present numerous opportunities for trust to break down. In particular, they note that trust can break down if the evidence generated by an analysis is not useful for decision-making. An alternative framework is proposed by Yu and Barter (2024), who argue that trustworthiness in the data science life cycle can be achieved through building analyses that have predictability, computability, and stability. A principle that ties both frameworks together is the characterization of the development of trust as primarily being in the hands of the analyst, via decisions made about study design, data collection, model choice, and other aspects of the data science process.\nOne approach to addressing the challenge of building a useful analysis is to consider the audience as part of the design of the analysis itself. Hence, it can be a valuable exercise to think about who the audience is that you (as the data analyst) have in mind when you build the data analysis. Some examples of who a data analysis write up is written for could include:\n\nA primary non-technical audience: This could be a collaborator or client. They might be interested a higher-level, non-technical pass of the write up (primarily focused on the introduction, main figures, and conclusions to find out what you learned). They may or may not read the technical details to see if there is something that stands out or unexpected. Here you want to think about building your data analysis with their expertise in mind where you prioritize the type of information that they found most relevant in a data analysis (for example, maybe they need to see a specific type of plot) and then move more of the technical details to the appendix.\nA secondary non-technical audience: This is likely a non-technical manager, an executive, or someone who is crafting new policies based the results of your data analysis. These individuals will skim most of the components of your analysis and will be focused on the “headlines” of your work. You want to summarize your key findings clearly and succinctly.\nA primary or secondary technical audience: This could be a technical manager or an advisor. Here, this individual will carefully read all components, including the main technical details in your data analysis. They may challenge you to justify your data analytic choices and push you to improve your technical writing, your code, and data visualizations. Here, you want to make sure the details of your report are easily readable, succinct (not a list of everything you did over the whole analysis), and compelling to justify the results you summarize in the conclusions.\n\n\n\n\n\n\n\nNote\n\n\n\nFor more information on the audience of a data analysis, I encourage you to read Quantifying the Alignment of a Data Analysis Between Analyst and Audience (McGowan, Peng, and Hicks 2025)."
  },
  {
    "objectID": "readings/00-best-practices-data-analysis/index.html#structure",
    "href": "readings/00-best-practices-data-analysis/index.html#structure",
    "title": "(Some) Best practices for writing up a data analysis",
    "section": "",
    "text": "Now that you have an audience in mind, the next question you might have is how to structure a data analysis. This is typically different from other professional writing you have done (e.g. research article for a peer-reviewed journal) because the structure of analyses can vary so much depending on the audience. In traditional research articles, there is typically less flexibility. The other thing I should add is that this is not a skill people are born with it. It takes practice to hone this skill of writing good data analyses and the more you do it, the easier it will become.\nGenerally speaking though, the structure of data analysis will include:\n\nAn introduction and/or motivation of the problem being addressed\nWhat is the question being asked that you will then investigate with data?\nThe body (may or may not include many of the technical details)\nKey conclusions and/or discussion of limitations of the data analysis\nAppendix (where often more of the technical detail goes if writing for a non-technical audience)\n\nThe ``body” is often quite different depending on who the audience is. You want to describe the computational approach(es) you took to investigate the question asked with the data available. Ideally, you are concise, but also it has to be informative.\nFor example, instead of saying “I used regression”, you could say “I fit a linear regression model to the price of diamonds using the size and clarity of the diamond as predictors”. You want to justify why these are relevant features and the body will often contain many plots or tables. This choice is up to you, but if you think a plot would be helpful to include to explain to the audience an important detail, then include it. You don’t want to include dozens or hundreds of plots without explanation or rationale why you included these plots.\n\n\nSome things to consider are:\n\nWho is your intended audience for the data analysis?\nWhat is the question you are trying to answer?\nWhy is this question important or interesting? If appropriate, mention prior work or background that motivated this analysis\nWhat data are you using? Identify the dataset(s), their source, and key features. This should be concise as the data can be described in greater detail elsewhere in the write up.\nWhat is the expected contribution or insight? What does this analysis add or clarify?\n\n\n\n\nSome things to consider are:\n\nYou want to clearly label figures, give them informative captions, and refer to them in the text in the order they in the paper (e.g. Figure 1, 2, 3, etc).\nShowing the code could be fine for certain audiences, but it could also be useful to just show the output of the code for other audiences as evidence for the results you summarize in the conclusions.\n\n\n\n\nSome things to consider are:\n\nWhat did you learn from the analysis?\nWhat are the limiations of the data used or the data analysis?\nWere you able to answer the original question asked or a different question?"
  },
  {
    "objectID": "readings/00-best-practices-data-analysis/index.html#some-dos-and-donts",
    "href": "readings/00-best-practices-data-analysis/index.html#some-dos-and-donts",
    "title": "(Some) Best practices for writing up a data analysis",
    "section": "",
    "text": "When in doubt, use shorter words and sentences.\nA common pitfall in report writing is to recount your thought process step by step — for example: “First I did this, but it didn’t work. Then I tried something else and found A, B, and C. I wasn’t sure what to make of B, but C seemed interesting, so I followed up with D and E.” Avoid this approach. While your attention to detail is commendable, this style comes across as unpolished and unfocused."
  }
]